sysFilePath = /storage/osg-otte1/shared/TrinityDemonstrator
container_image = $(sysFilePath)/DataAnalysis/containers/rootandexact.sif

# Ensure host paths are visible inside the container
#+ApptainerBind = "/storage,/tmp,/dev,/proc,/exact"


executable = run_condor.sh
 # name of the bash script or python or root 

# add user arg and getenv = True
# add folder arg t use in .logs paths????
arguments = $(Date) $(Filename) $ENV(USER) $(folder)
getenv = True

# Keep your environment variables
#getenv = False

# include user 
# add $(folder) after /.logs/ ??
log = $(sysFilePath)/DataAnalysis/MergedData/.logs/HT_condor_$ENV(USER)_$(Date)_$(Filename).log 
# HTCondor log

# include user 
# need to figure out how to make LS_MergedFiles user specific!! - change to $(folder)??
# error = $(sysFilePath)/DataAnalysis/MergedData/.logs/LS_MergedFiles/Program_$ENV(USER)_$(Date)_$(Filename).err
error = $(sysFilePath)/DataAnalysis/MergedData/.logs/$(folder)/Program_$ENV(USER)_$(Date)_$(Filename).err 

#Standard Error - program and HTCondor errors

# include user 
# need to figure out how to make LS_MergedFiles user specific!! - change to $(folder)??
output = $(sysFilePath)/DataAnalysis/MergedData/.logs/$(folder)/Program_$ENV(USER)_$(Date)_$(Filename).out 
# program terminal output (not output files)


transfer_input_files = $(sysFilePath)/Data/$(Date)/RawDataMerged/$(Filename),$(sysFilePath)/DataAnalysis/MergedData/scripts/MergeData/FileMerge,$(sysFilePath)/DataAnalysis/MergedData/scripts/IncludeCalibrationData/AddCalibData, $(sysFilePath)/DataAnalysis/MergedData/run_condor.sh,$(sysFilePath)/DataAnalysis/containers/rootandexact.sif,$(sysFilePath)/DataAnalysis/AncillaryData/Data2/statemessages$(Date).csv,$(sysFilePath)/DataAnalysis/AncillaryData/Data1/celestialPositions$(Date).csv,$(sysFilePath)/MiscData/WeatherData/weather/weather_$(Date),$(sysFilePath)/DataAnalysis/exact/data/SiPMTempatureCorrections.csv,,$(sysFilePath)/DataAnalysis/exact/data/UCTempatureCorrections.csv
#any file that needs to included for the job - everything minus executable



should_transfer_files = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
# deleted $DATE from end of path ?
transfer_output_files = DataAnalysis/MergedData/Output/


request_cpus = 1
 # these are PER JOB

request_memory = 1GB 
# these are PER JOB

JobBatchName = "MD_$(Date)"

# space for all files input and output and intermediate files
request_disk = 10GB 
# these are PER JOB

# Tell HTCondor to run 3 instances of our job:
###----------#####
# Queue! HAS TO BE THE LAST LINE
###----------#####
# MAGICAL
# synatax 
# queue + num - que this many identical jobs (EXACT  SAME JOB)
# use case - executable can create independent jobs (script creates difference between jobs)
# randomw number simulations 
queue Filename from $(sysFilePath)/DataAnalysis/data_lists/file_list_$(Date).txt