sysFilePath = /storage/osg-otte1/shared/TrinityDemonstrator
container_image = $(sysFilePath)/DataAnalysis/containers/rootandexact.sif

# Ensure host paths are visible inside the container
#+ApptainerBind = "/storage,/tmp,/dev,/proc,/exact"


executable = run_condor.sh
 # name of the bash script or python or root 

# add user arg and getenv = True
arguments = $(Date) $(Filename) $ENV(USER)
getenv = True
# added from event_cleaning condense_SM.submit

# Keep your environment variables
#getenv = False

# add user env to path also to filename
log = $(sysFilePath)/DataAnalysis/MergedData/.logs/$ENV(USER)/HT_condor__$ENV(USER)$(Date)_$(Filename).log 
# HTCondor log

# add user env to path and filename
error = $(sysFilePath)/DataAnalysis/MergedData/.logs/$ENV(USER)/Program__$ENV(USER)$(Date)_$(Filename).err 
#Standard Error - program and HTCondor errors

# add user env to path and filename
output = $(sysFilePath)/DataAnalysis/MergedData/.logs/$ENV(USER)/Program__$ENV(USER)$(Date)_$(Filename).out 
# program terminal output (not output files)


transfer_input_files = $(sysFilePath)/Data/$(Date)/RawDataMerged/$(Filename),$(sysFilePath)/DataAnalysis/MergedData/scripts/MergeData/FileMerge,$(sysFilePath)/DataAnalysis/MergedData/scripts/IncludeCalibrationData/AddCalibData, $(sysFilePath)/DataAnalysis/MergedData/run_condor.sh,$(sysFilePath)/DataAnalysis/containers/rootandexact.sif,$(sysFilePath)/DataAnalysis/AncillaryData/Data2/statemessages$(Date).csv,$(sysFilePath)/DataAnalysis/AncillaryData/Data1/celestialPositions$(Date).csv,$(sysFilePath)/MiscData/WeatherData/weather/weather_$(Date),$(sysFilePath)/DataAnalysis/exact/data/SiPMTempatureCorrections.csv,,$(sysFilePath)/DataAnalysis/exact/data/UCTempatureCorrections.csv
#any file that needs to included for the job - everything minus executable



should_transfer_files = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
# deleted $DATE from end of path ?
transfer_output_files = DataAnalysis/MergedData/Output/


request_cpus = 1
 # these are PER JOB

request_memory = 1GB 
# these are PER JOB

JobBatchName = "MD_$(Date)"

# space for all files input and output and intermediate files
request_disk = 10GB 
# these are PER JOB

# Tell HTCondor to run 3 instances of our job:
###----------#####
# Queue! HAS TO BE THE LAST LINE
###----------#####
# MAGICAL
# synatax 
# queue + num - que this many identical jobs (EXACT  SAME JOB)
# use case - executable can create independent jobs (script creates difference between jobs)
# randomw number simulations 
queue Filename from $(sysFilePath)/DataAnalysis/data_lists/file_list_$(Date).txt