sysFilePath = /storage/osg-otte1/shared/TrinityDemonstrator
container_image = $(sysFilePath)/DataAnalysis/containers/rootandexact.sif

# Ensure host paths are visible inside the container
#+ApptainerBind = "/storage,/tmp,/dev,/proc,/exact"


executable = run_condor.sh
 # name of the bash script or python or root 

arguments = $(Date) $(Filename) $ENV(USER)
getenv = True

# Keep your environment variables
#getenv = False

## added user env
log = $(sysFilePath)/DataAnalysis/event_cleaning/.logs/$ENV(USER)/HT_condor_$ENV(USER)_$(Date)_$(Filename).log 
# HTCondor log

## added user env
error = $(sysFilePath)/DataAnalysis/event_cleaning/.logs/$ENV(USER)/Program_$ENV(USER)_$(Date)_$(Filename).err 
#Standard Error - program and HTCondor errors

## added user env
output = $(sysFilePath)/DataAnalysis/event_cleaning/.logs/$ENV(USER)/Program_$ENV(USER)_$(Date)_$(Filename).out 
# program terminal output (not output files)

# add folder arg to paths
transfer_input_files = $(sysFilePath)/DataAnalysis/MergedData/Output/$ENV(USER)/$(Date)/$(Filename),\
$(sysFilePath)/DataAnalysis/event_cleaning/ClusterCleaning/EventCleaning,\
$(sysFilePath)/DataAnalysis/event_cleaning/ClusterCleaning/EventInfoDict_rdict.pcm,\
$(sysFilePath)/DataAnalysis/event_cleaning/ClusterCleaning/EventInfo.h,\
$(sysFilePath)/DataAnalysis/event_cleaning/ClusterCleaning/LinkDef.h,\
$(sysFilePath)/DataAnalysis/event_cleaning/ClusterCleaning/neighbors, \
$(sysFilePath)/DataAnalysis/event_cleaning/run_condor.sh,\
$(sysFilePath)/DataAnalysis/containers/rootandexact.sif,\
$(sysFilePath)/DataAnalysis/flasher_calibration/Output/$ENV(USER)/$(Date)_FlasherCalibration_Factor.root
#any file that needs to included for the job - everything minus executable
#might need to change file path for flasher_calibration for user directory



should_transfer_files = YES
when_to_transfer_output = ON_EXIT_OR_EVICT
transfer_output_files = DataAnalysis/event_cleaning/Output



request_cpus = 1
 # these are PER JOB

request_memory = 1GB 
# these are PER JOB

# space for all files input and output and intermediate files
request_disk = 4GB 
max_retries=3
# these are PER JOB

JobBatchName = "EC_$(Date)"

# Tell HTCondor to run 3 instances of our job:
###----------#####
# Queue! HAS TO BE THE LAST LINE
###----------#####
# MAGICAL
# synatax 
# queue + num - que this many identical jobs (EXACT  SAME JOB)
# use case - executable can create independent jobs (script creates difference between jobs)
# randomw number simulations 
queue Filename from $(sysFilePath)/DataAnalysis/data_lists/file_list_$(Date).txt
 

